{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5610d977",
   "metadata": {},
   "source": [
    "# Function form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7f8be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lifesciencehack-ai.hatenablog.com/entry/2020/08/07/Python%E3%81%A7%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A5%EF%BD%9EEFetch%E3%82%92%E4%BD%BF\n",
    "\n",
    "import json\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def eSearch(term, retmax=10):\n",
    "    URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json'\n",
    "    option = '&retmax='+str(retmax)+'&term='+term\n",
    "    query = URL + option\n",
    "    response = requests.get(query)\n",
    "    response_json = response.json()\n",
    "    pmids = response_json['esearchresult']['idlist']\n",
    "    return pmids\n",
    "\n",
    "def eSummary(pmids):\n",
    "    URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&retmode=json&id='\n",
    "    queries = [URL + pmid for pmid in pmids]\n",
    "    responses = {}\n",
    "    for query in queries:\n",
    "        response = requests.get(query)\n",
    "        res_json = response.json()['result']\n",
    "        responses.update(res_json)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    Summaries = [{'pmid':pmid,\n",
    "                  'Title':responses[pmid]['title'], \n",
    "                  'Author':responses[pmid]['sortfirstauthor'],\n",
    "                  'Journal_full' : responses[pmid]['fulljournalname'],\n",
    "                  'Journal_abbr' : responses[pmid]['source'],\n",
    "                  'Pubdate':responses[pmid]['epubdate']} for pmid in pmids]\n",
    "    return pd.DataFrame(Summaries)\n",
    "\n",
    "def eFetch(pmids):\n",
    "    URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id='\n",
    "\n",
    "    queries = [URL + pmid for pmid in pmids]\n",
    "\n",
    "    responses_abst = {}\n",
    "\n",
    "    for query in queries:\n",
    "        response = requests.get(query)\n",
    "        root = etree.fromstring(response.content)\n",
    "        pmid = root.find('.//PMID').text#pmidを抽出\n",
    "        abst = root.findall('.//AbstractText')\n",
    "        if abst is None:\n",
    "            abst_text = ''\n",
    "        else:\n",
    "            abst_text = ''.join(root.xpath('//Abstract//*/text()'))\n",
    "        responses_abst[pmid]=abst_text\n",
    "        time.sleep(0.2)\n",
    "        abst_df = pd.DataFrame.from_dict(responses_abst, orient='index')\n",
    "        abst_df.index.name = 'pmid'\n",
    "        abst_df.columns = ['Abstract']\n",
    "    \n",
    "    return abst_df\n",
    "\n",
    "def to_excel(data, filename):\n",
    "    # https://lifesciencehack-ai.hatenablog.com/entry/2019/02/23/Python%E3%81%A7%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A4_~_Excel%E3%83%95%E3%82%A1%E3%82%A4\n",
    "\n",
    "    wb = openpyxl.Workbook() #ワークブックの作成\n",
    "    ws = wb.active #ワークブックのアクティブになってるシートを選択\n",
    "    ws.title='論文' #シートの名前を変更\n",
    "\n",
    "    #フォントの設定\n",
    "    normal_font = Font(name = \"Century Gothic\",sz = 9,b = False)\n",
    "    header_font = Font(name = \"Century Gothic\", sz = 9, b = True, color = 'FFFFFFFF')\n",
    "    #ヘッダーの塗りの設定\n",
    "    header_fill = PatternFill(patternType = \"solid\", fgColor = \"FF808080\")\n",
    "    #ヘッダーを中央揃えにする設定\n",
    "    header_center = Alignment(horizontal='center',vertical = 'center')    \n",
    "    #ヘッダーを太字にする設定\n",
    "    header_border = Border(\n",
    "            outline=True,\n",
    "            left=Side(style='thin', color='FF000000'),\n",
    "            right=Side(style='thin', color='FF000000'),\n",
    "            top=Side(style='thin', color='FF000000'),\n",
    "            bottom=Side(style='thin', color='FF000000')\n",
    "            )\n",
    "\n",
    "    for r in dataframe_to_rows(data, index=False, header=True):\n",
    "        ws.append(r)\n",
    "\n",
    "    for row in ws:\n",
    "        for cell in row:\n",
    "            cell.font = normal_font\n",
    "\n",
    "    header_cell = ['A1', 'B1', 'C1', 'D1', 'E1']\n",
    "    for cell in header_cell:\n",
    "        ws[cell].font = header_font\n",
    "        ws[cell].fill = header_fill\n",
    "        ws[cell].alignment = header_center\n",
    "        ws[cell].border = header_border\n",
    "\n",
    "    wb.save(filename)      \n",
    "\n",
    "def to_chat_AI(data, filename):\n",
    "    l_data = data[[\"pmid\", \"Title\", \"Abstract\"]].values.tolist()\n",
    "    l_data = [\"pmid:\" + l[0] + \", title:\" + l[1] + \", abstract:\" + l[2] for l in l_data]\n",
    "    str_data = \"\\n\\n\".join(l_data)\n",
    "    with open(filename, \"w\", encoding='UTF-8') as f:\n",
    "        f.write(str_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e4dd16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Journal_full</th>\n",
       "      <th>Journal_abbr</th>\n",
       "      <th>Pubdate</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36800255</td>\n",
       "      <td>A partial convolution generative adversarial n...</td>\n",
       "      <td>Liu Y</td>\n",
       "      <td>Journal of applied clinical medical physics</td>\n",
       "      <td>J Appl Clin Med Phys</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Lesion segmentation is critical for clinicians...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36800155</td>\n",
       "      <td>Few-shot learning using explainable Siamese tw...</td>\n",
       "      <td>Tummala S</td>\n",
       "      <td>Medical &amp; biological engineering &amp; computing</td>\n",
       "      <td>Med Biol Eng Comput</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Automated classification of blood cells from m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36800143</td>\n",
       "      <td>Segmentation of the aorta in systolic phase fr...</td>\n",
       "      <td>Marin-Castrillon DM</td>\n",
       "      <td>Magma (New York, N.Y.)</td>\n",
       "      <td>MAGMA</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>In the management of the aortic aneurysm, 4D f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36800112</td>\n",
       "      <td>Diagnostic performance of deep learning-based ...</td>\n",
       "      <td>Yang W</td>\n",
       "      <td>La Radiologia medica</td>\n",
       "      <td>Radiol Med</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Post-processing and interpretation of coronary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36799660</td>\n",
       "      <td>Using Explainable Artificial Intelligence in t...</td>\n",
       "      <td>Jiménez-Mesa C</td>\n",
       "      <td>International journal of neural systems</td>\n",
       "      <td>Int J Neural Syst</td>\n",
       "      <td>2023 Feb 16</td>\n",
       "      <td>The prevalence of dementia is currently increa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36799418</td>\n",
       "      <td>An innovative metal artifact reduction algorit...</td>\n",
       "      <td>Zhang Z</td>\n",
       "      <td>Current medical imaging</td>\n",
       "      <td>Curr Med Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>During X-ray computed tomography (CT) scans, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36799417</td>\n",
       "      <td>Cancer detection based on Medical Image Analys...</td>\n",
       "      <td>Sood T</td>\n",
       "      <td>Current medical imaging</td>\n",
       "      <td>Curr Med Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Cancer is a deadly disease. It is crucial to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36799341</td>\n",
       "      <td>Implementable Deep Learning for Multi-sequence...</td>\n",
       "      <td>Astley JR</td>\n",
       "      <td>Journal of magnetic resonance imaging : JMRI</td>\n",
       "      <td>J Magn Reson Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Recently, deep learning via convolutional neur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36799277</td>\n",
       "      <td>Micromirrors in Neurosurgery: Technical Overvi...</td>\n",
       "      <td>Ordóñez-Rubiano EG</td>\n",
       "      <td>Turkish neurosurgery</td>\n",
       "      <td>Turk Neurosurg</td>\n",
       "      <td>2022 Aug 26</td>\n",
       "      <td>Micromirrors are 45°-angled reflectors able to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36799198</td>\n",
       "      <td>Construction of Exosome SORL1 Detection Platfo...</td>\n",
       "      <td>Li P</td>\n",
       "      <td>Small (Weinheim an der Bergstrasse, Germany)</td>\n",
       "      <td>Small</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Exosomes are promising new biomarkers for colo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              Title  \\\n",
       "0  36800255  A partial convolution generative adversarial n...   \n",
       "1  36800155  Few-shot learning using explainable Siamese tw...   \n",
       "2  36800143  Segmentation of the aorta in systolic phase fr...   \n",
       "3  36800112  Diagnostic performance of deep learning-based ...   \n",
       "4  36799660  Using Explainable Artificial Intelligence in t...   \n",
       "5  36799418  An innovative metal artifact reduction algorit...   \n",
       "6  36799417  Cancer detection based on Medical Image Analys...   \n",
       "7  36799341  Implementable Deep Learning for Multi-sequence...   \n",
       "8  36799277  Micromirrors in Neurosurgery: Technical Overvi...   \n",
       "9  36799198  Construction of Exosome SORL1 Detection Platfo...   \n",
       "\n",
       "                Author                                  Journal_full  \\\n",
       "0                Liu Y   Journal of applied clinical medical physics   \n",
       "1            Tummala S  Medical & biological engineering & computing   \n",
       "2  Marin-Castrillon DM                        Magma (New York, N.Y.)   \n",
       "3               Yang W                          La Radiologia medica   \n",
       "4       Jiménez-Mesa C       International journal of neural systems   \n",
       "5              Zhang Z                       Current medical imaging   \n",
       "6               Sood T                       Current medical imaging   \n",
       "7            Astley JR  Journal of magnetic resonance imaging : JMRI   \n",
       "8   Ordóñez-Rubiano EG                          Turkish neurosurgery   \n",
       "9                 Li P  Small (Weinheim an der Bergstrasse, Germany)   \n",
       "\n",
       "           Journal_abbr      Pubdate  \\\n",
       "0  J Appl Clin Med Phys  2023 Feb 17   \n",
       "1   Med Biol Eng Comput  2023 Feb 17   \n",
       "2                 MAGMA  2023 Feb 17   \n",
       "3            Radiol Med  2023 Feb 17   \n",
       "4     Int J Neural Syst  2023 Feb 16   \n",
       "5      Curr Med Imaging  2023 Feb 17   \n",
       "6      Curr Med Imaging  2023 Feb 17   \n",
       "7  J Magn Reson Imaging  2023 Feb 17   \n",
       "8        Turk Neurosurg  2022 Aug 26   \n",
       "9                 Small  2023 Feb 17   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Lesion segmentation is critical for clinicians...  \n",
       "1  Automated classification of blood cells from m...  \n",
       "2  In the management of the aortic aneurysm, 4D f...  \n",
       "3  Post-processing and interpretation of coronary...  \n",
       "4  The prevalence of dementia is currently increa...  \n",
       "5  During X-ray computed tomography (CT) scans, t...  \n",
       "6  Cancer is a deadly disease. It is crucial to d...  \n",
       "7  Recently, deep learning via convolutional neur...  \n",
       "8  Micromirrors are 45°-angled reflectors able to...  \n",
       "9  Exosomes are promising new biomarkers for colo...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pubmedで検索する単語をtermとします。「%20」はスペースです。\n",
    "term = 'deep%20learning'\n",
    "\n",
    "#まずはeSearchでpmidを取得します。デフォルトでは10個までにしましたが、変更する際はretmax=100などを入れます。\n",
    "pmids = eSearch(term)\n",
    "\n",
    "#論文の基本情報を取得し、pandasのDataFrame型として返します。\n",
    "summary_df = eSummary(pmids)\n",
    "\n",
    "#更にアブストラクトをeFetchで取得し、pandas DataFrame型として返す。\n",
    "abst_df = eFetch(pmids)\n",
    "\n",
    "#summaryとabstractを統合し一つのDataFrameとします。\n",
    "df = pd.merge(summary_df, abst_df, on='pmid')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47ed7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_excel(df, \"test2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69b3bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_chat_AI(df, \"test2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c710cd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0050b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1fe676b",
   "metadata": {},
   "source": [
    "# Non-function form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdc6b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lifesciencehack-ai.hatenablog.com/entry/Python%E3%81%A7%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A1%E4%B8%8B%E6%BA%96%E5%82%99\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import Border, Font, Side, PatternFill, Alignment\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32ec03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "application/json; charset=UTF-8\n",
      "{'header': {'type': 'esearch', 'version': '0.3'}, 'esearchresult': {'count': '53431', 'retmax': '10', 'retstart': '0', 'idlist': ['36800255', '36800155', '36800143', '36800112', '36799660', '36799418', '36799417', '36799341', '36799277', '36799198'], 'translationset': [{'from': 'deep learning', 'to': '\"deep learning\"[MeSH Terms] OR (\"deep\"[All Fields] AND \"learning\"[All Fields]) OR \"deep learning\"[All Fields]'}], 'querytranslation': '\"deep learning\"[MeSH Terms] OR (\"deep\"[All Fields] AND \"learning\"[All Fields]) OR \"deep learning\"[All Fields]'}}\n",
      "['36800255', '36800155', '36800143', '36800112', '36799660', '36799418', '36799417', '36799341', '36799277', '36799198']\n"
     ]
    }
   ],
   "source": [
    "# https://lifesciencehack-ai.hatenablog.com/entry/%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A2ESearch%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6PMID%E3%82%92%E5%8F%96\n",
    "query = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=deep+learning&retmax=10&retmode=json'\n",
    "\n",
    "response = requests.get(query)\n",
    "\n",
    "print(response)\n",
    "# <Response [200]>  「200だとうまくいっています。200以外だとqueryがうまく書けてない可能性があります」\n",
    "\n",
    "print(response.headers['Content-Type'])\n",
    "# 'application/json; charset=UTF-8'　「json形式でデータを取得できていることが確認できました」\n",
    "\n",
    "response_json = response.json()\n",
    "print(response_json)\n",
    "\n",
    "# {'header': {'type': 'esearch', 'version': '0.3'}, \n",
    "#'esearchresult': {'count': '6868', 'retmax': '10', 'retstart': '0', 'idlist': ['30481649', '30481453', '30481205', '30481176', '30481151', '30480818', '30480490', '30480079', '30478928', '30478810'], \n",
    "#'translationset': [{'from': 'learning', 'to': '\"learning\"[MeSH Terms] OR \"learning\"[All Fields]'}],\n",
    "# 'translationstack': [{'term': 'deep[All Fields]', 'field': 'All Fields', 'count': '197588', 'explode': 'N'}, {'term': '\"learning\"[MeSH Terms]', 'field': 'MeSH Terms', 'count': '356271', 'explode': 'Y'}, {'term': '\"learning\"[All Fields]', 'field': 'All Fields', 'count': '344322', 'explode': 'N'}, 'OR', 'GROUP', 'AND', 'GROUP'], #'querytranslation': 'deep[All Fields] AND (\"learning\"[MeSH Terms] OR \"learning\"[All Fields])'}}\n",
    "\n",
    "pmids = response_json['esearchresult']['idlist']\n",
    "print(pmids)\n",
    "# ['30481649', '30481453', '30481205', '30481176', '30481151', '30480818', '30480490', '30480079', '30478928', '30478810']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfdad562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uid': '36799198', 'pubdate': '2023 Feb 17', 'epubdate': '2023 Feb 17', 'source': 'Small', 'authors': [{'name': 'Li P', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Chen J', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Chen Y', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Song S', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Huang X', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Yang Y', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Li Y', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Tong Y', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Xie Y', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Li J', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Li S', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Wang J', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Qian K', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Wang C', 'authtype': 'Author', 'clusterid': ''}, {'name': 'Du L', 'authtype': 'Author', 'clusterid': ''}], 'lastauthor': 'Du L', 'title': 'Construction of Exosome SORL1 Detection Platform Based on 3D Porous Microfluidic Chip and its Application in Early Diagnosis of Colorectal Cancer.', 'sorttitle': 'construction of exosome sorl1 detection platform based on 3d porous microfluidic chip and its application in early diagnosis of colorectal cancer', 'volume': '', 'issue': '', 'pages': 'e2207381', 'lang': ['eng'], 'nlmuniqueid': '101235338', 'issn': '1613-6810', 'essn': '1613-6829', 'pubtype': ['Journal Article'], 'recordstatus': 'PubMed - as supplied by publisher', 'pubstatus': '10', 'articleids': [{'idtype': 'pubmed', 'idtypen': 1, 'value': '36799198'}, {'idtype': 'doi', 'idtypen': 3, 'value': '10.1002/smll.202207381'}], 'history': [{'pubstatus': 'revised', 'date': '2023/01/29 00:00'}, {'pubstatus': 'received', 'date': '2022/11/27 00:00'}, {'pubstatus': 'entrez', 'date': '2023/02/17 04:35'}, {'pubstatus': 'pubmed', 'date': '2023/02/18 06:00'}, {'pubstatus': 'medline', 'date': '2023/02/18 06:00'}], 'references': [], 'attributes': ['Has Abstract'], 'pmcrefcount': '', 'fulljournalname': 'Small (Weinheim an der Bergstrasse, Germany)', 'elocationid': 'doi: 10.1002/smll.202207381', 'doctype': 'citation', 'srccontriblist': [], 'booktitle': '', 'medium': '', 'edition': '', 'publisherlocation': '', 'publishername': '', 'srcdate': '', 'reportnumber': '', 'availablefromurl': '', 'locationlabel': '', 'doccontriblist': [], 'docdate': '', 'bookname': '', 'chapter': '', 'sortpubdate': '2023/02/17 00:00', 'sortfirstauthor': 'Li P', 'vernaculartitle': ''}\n",
      "\n",
      "keys\n",
      "dict_keys(['uid', 'pubdate', 'epubdate', 'source', 'authors', 'lastauthor', 'title', 'sorttitle', 'volume', 'issue', 'pages', 'lang', 'nlmuniqueid', 'issn', 'essn', 'pubtype', 'recordstatus', 'pubstatus', 'articleids', 'history', 'references', 'attributes', 'pmcrefcount', 'fulljournalname', 'elocationid', 'doctype', 'srccontriblist', 'booktitle', 'medium', 'edition', 'publisherlocation', 'publishername', 'srcdate', 'reportnumber', 'availablefromurl', 'locationlabel', 'doccontriblist', 'docdate', 'bookname', 'chapter', 'sortpubdate', 'sortfirstauthor', 'vernaculartitle'])\n",
      "\n",
      "title\n",
      "Construction of Exosome SORL1 Detection Platform Based on 3D Porous Microfluidic Chip and its Application in Early Diagnosis of Colorectal Cancer.\n",
      "\n",
      "fulljournalname\n",
      "Small (Weinheim an der Bergstrasse, Germany)\n",
      "\n",
      "source\n",
      "Small\n"
     ]
    }
   ],
   "source": [
    "# https://lifesciencehack-ai.hatenablog.com/entry/2018/12/04/Python%E3%81%A7%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A3_~_ESummary%E3%82%92%E4%BD%BF%E3%81%A3\n",
    "\n",
    "import requests\n",
    "\n",
    "URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&retmode=json&id='\n",
    "\n",
    "queries = [URL + pmid for pmid in pmids]\n",
    "# pmids は前回の記事で取得したpmidのリストです。\n",
    "\n",
    "responses = {} #このあと取得するjsonデータを格納する辞書を作成\n",
    "\n",
    "for query in queries:\n",
    "      response = requests.get(query)\n",
    "      res_json = response.json()['result'] #responseのjsonを取得し、その中のresultを返す\n",
    "      responses.update(res_json) #res_jsonをresponsesに連結\n",
    "\n",
    "key1 = '36799198'\n",
    "\n",
    "print(responses[key1])\n",
    "print()\n",
    "print(\"keys\")\n",
    "print(responses[key1].keys())\n",
    "print()\n",
    "print(\"title\")\n",
    "print(responses[key1]['title']) #pmid = 30478810のタイトルを取得\n",
    "#Deep convolutional neural network-based speech enhancement to improve speech intelligibility and quality for hearing-impaired listeners.\n",
    "\n",
    "print()\n",
    "print(\"fulljournalname\")\n",
    "print(responses[key1]['fulljournalname']) # pmid = 30478810のジャーナルフルネームを取得\n",
    "#Medical &amp; biological engineering &amp; computing 文字化け\n",
    "\n",
    "print()\n",
    "print(\"source\")\n",
    "print(responses[key1]['source']) #pmid = 30478810のジャーナル略称を取得\n",
    "#Med Biol Eng Comput\n",
    "\n",
    "Summaries = [{'pmid':pmid, \n",
    "'Title':responses[pmid]['title'], \n",
    "'Author':responses[pmid]['sortfirstauthor'],\n",
    "'Journal_full' : responses[pmid]['fulljournalname'],\n",
    "'Journal_abbr' : responses[pmid]['source'],\n",
    "'Pubdate':responses[pmid]['epubdate']} for pmid in pmids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e28ff97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Journal_full</th>\n",
       "      <th>Journal_abbr</th>\n",
       "      <th>Pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36800255</td>\n",
       "      <td>A partial convolution generative adversarial n...</td>\n",
       "      <td>Liu Y</td>\n",
       "      <td>Journal of applied clinical medical physics</td>\n",
       "      <td>J Appl Clin Med Phys</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36800155</td>\n",
       "      <td>Few-shot learning using explainable Siamese tw...</td>\n",
       "      <td>Tummala S</td>\n",
       "      <td>Medical &amp; biological engineering &amp; computing</td>\n",
       "      <td>Med Biol Eng Comput</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36800143</td>\n",
       "      <td>Segmentation of the aorta in systolic phase fr...</td>\n",
       "      <td>Marin-Castrillon DM</td>\n",
       "      <td>Magma (New York, N.Y.)</td>\n",
       "      <td>MAGMA</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36800112</td>\n",
       "      <td>Diagnostic performance of deep learning-based ...</td>\n",
       "      <td>Yang W</td>\n",
       "      <td>La Radiologia medica</td>\n",
       "      <td>Radiol Med</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36799660</td>\n",
       "      <td>Using Explainable Artificial Intelligence in t...</td>\n",
       "      <td>Jiménez-Mesa C</td>\n",
       "      <td>International journal of neural systems</td>\n",
       "      <td>Int J Neural Syst</td>\n",
       "      <td>2023 Feb 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36799418</td>\n",
       "      <td>An innovative metal artifact reduction algorit...</td>\n",
       "      <td>Zhang Z</td>\n",
       "      <td>Current medical imaging</td>\n",
       "      <td>Curr Med Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36799417</td>\n",
       "      <td>Cancer detection based on Medical Image Analys...</td>\n",
       "      <td>Sood T</td>\n",
       "      <td>Current medical imaging</td>\n",
       "      <td>Curr Med Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36799341</td>\n",
       "      <td>Implementable Deep Learning for Multi-sequence...</td>\n",
       "      <td>Astley JR</td>\n",
       "      <td>Journal of magnetic resonance imaging : JMRI</td>\n",
       "      <td>J Magn Reson Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36799277</td>\n",
       "      <td>Micromirrors in Neurosurgery: Technical Overvi...</td>\n",
       "      <td>Ordóñez-Rubiano EG</td>\n",
       "      <td>Turkish neurosurgery</td>\n",
       "      <td>Turk Neurosurg</td>\n",
       "      <td>2022 Aug 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36799198</td>\n",
       "      <td>Construction of Exosome SORL1 Detection Platfo...</td>\n",
       "      <td>Li P</td>\n",
       "      <td>Small (Weinheim an der Bergstrasse, Germany)</td>\n",
       "      <td>Small</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              Title  \\\n",
       "0  36800255  A partial convolution generative adversarial n...   \n",
       "1  36800155  Few-shot learning using explainable Siamese tw...   \n",
       "2  36800143  Segmentation of the aorta in systolic phase fr...   \n",
       "3  36800112  Diagnostic performance of deep learning-based ...   \n",
       "4  36799660  Using Explainable Artificial Intelligence in t...   \n",
       "5  36799418  An innovative metal artifact reduction algorit...   \n",
       "6  36799417  Cancer detection based on Medical Image Analys...   \n",
       "7  36799341  Implementable Deep Learning for Multi-sequence...   \n",
       "8  36799277  Micromirrors in Neurosurgery: Technical Overvi...   \n",
       "9  36799198  Construction of Exosome SORL1 Detection Platfo...   \n",
       "\n",
       "                Author                                  Journal_full  \\\n",
       "0                Liu Y   Journal of applied clinical medical physics   \n",
       "1            Tummala S  Medical & biological engineering & computing   \n",
       "2  Marin-Castrillon DM                        Magma (New York, N.Y.)   \n",
       "3               Yang W                          La Radiologia medica   \n",
       "4       Jiménez-Mesa C       International journal of neural systems   \n",
       "5              Zhang Z                       Current medical imaging   \n",
       "6               Sood T                       Current medical imaging   \n",
       "7            Astley JR  Journal of magnetic resonance imaging : JMRI   \n",
       "8   Ordóñez-Rubiano EG                          Turkish neurosurgery   \n",
       "9                 Li P  Small (Weinheim an der Bergstrasse, Germany)   \n",
       "\n",
       "           Journal_abbr      Pubdate  \n",
       "0  J Appl Clin Med Phys  2023 Feb 17  \n",
       "1   Med Biol Eng Comput  2023 Feb 17  \n",
       "2                 MAGMA  2023 Feb 17  \n",
       "3            Radiol Med  2023 Feb 17  \n",
       "4     Int J Neural Syst  2023 Feb 16  \n",
       "5      Curr Med Imaging  2023 Feb 17  \n",
       "6      Curr Med Imaging  2023 Feb 17  \n",
       "7  J Magn Reson Imaging  2023 Feb 17  \n",
       "8        Turk Neurosurg  2022 Aug 26  \n",
       "9                 Small  2023 Feb 17  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(Summaries)\n",
    "data\n",
    "# # https://lifesciencehack-ai.hatenablog.com/entry/2019/02/23/Python%E3%81%A7%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A4_~_Excel%E3%83%95%E3%82%A1%E3%82%A4\n",
    "# data  = pd.DataFrame(columns = ['PMID','Title', 'Author', 'Journal', 'Pubdate'])\n",
    "# # カラム名を指定してデータフレームを作成\n",
    "# PMIDs = [ i['pmid'] for i in Summaries ]\n",
    "# Titles = [ i['Title'] for i in Summaries ]\n",
    "# Authors = [ i['Author'] for i in Summaries ]\n",
    "# Journals = [ i['Journal'] for i in  Summaries ]\n",
    "# Pubdates = [ i['Pubdate'] for i in Summaries ]\n",
    "# data['PMID'] = PMIDs\n",
    "# data['Title'] = Titles\n",
    "# data['Author'] = Authors\n",
    "# data['Journal'] = Journals\n",
    "# data['Pubdate'] = Pubdates\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3aa95c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lifesciencehack-ai.hatenablog.com/entry/2019/02/23/Python%E3%81%A7%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A4_~_Excel%E3%83%95%E3%82%A1%E3%82%A4\n",
    "\n",
    "wb = openpyxl.Workbook() #ワークブックの作成\n",
    "ws = wb.active #ワークブックのアクティブになってるシートを選択\n",
    "ws.title='論文' #シートの名前を変更\n",
    "\n",
    "#フォントの設定\n",
    "normal_font = Font(name = \"Century Gothic\",sz = 9,b = False)\n",
    "header_font = Font(name = \"Century Gothic\", sz = 9, b = True, color = 'FFFFFFFF')\n",
    "#ヘッダーの塗りの設定\n",
    "header_fill = PatternFill(patternType = \"solid\", fgColor = \"FF808080\")\n",
    "#ヘッダーを中央揃えにする設定\n",
    "header_center = Alignment(horizontal='center',vertical = 'center')    \n",
    "#ヘッダーを太字にする設定\n",
    "header_border = Border(\n",
    "        outline=True,\n",
    "        left=Side(style='thin', color='FF000000'),\n",
    "        right=Side(style='thin', color='FF000000'),\n",
    "        top=Side(style='thin', color='FF000000'),\n",
    "        bottom=Side(style='thin', color='FF000000')\n",
    "        )\n",
    "\n",
    "for r in dataframe_to_rows(data, index=False, header=True):\n",
    "    ws.append(r)\n",
    "    \n",
    "for row in ws:\n",
    "    for cell in row:\n",
    "        cell.font = normal_font\n",
    "    \n",
    "header_cell = ['A1', 'B1', 'C1', 'D1', 'E1']\n",
    "for cell in header_cell:\n",
    "    ws[cell].font = header_font\n",
    "    ws[cell].fill = header_fill\n",
    "    ws[cell].alignment = header_center\n",
    "    ws[cell].border = header_border\n",
    "\n",
    "wb.save(\"test.xlsx\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82dc0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lifesciencehack-ai.hatenablog.com/entry/2020/08/07/Python%E3%81%A7%E8%AB%96%E6%96%87%E6%83%85%E5%A0%B1%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E3%82%B2%E3%83%83%E3%83%88%E3%81%99%E3%82%8B%E2%91%A5%EF%BD%9EEFetch%E3%82%92%E4%BD%BF\n",
    "import requests\n",
    "from lxml import etree\n",
    "import time\n",
    "\n",
    "URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=XML &id='\n",
    "# EFetchの基本URL. これにpmidを追加してqueryとする\n",
    "\n",
    "queries = [URL + pmid for pmid in pmids]\n",
    "# pmids は第4回の記事で取得したpmidのリストです。\n",
    "\n",
    "responses_abst = {} #このあと取得するabstractを格納する辞書を作成\n",
    "\n",
    "# ESummaryの時はpmidごとのjsonすべてをresponseに保存していたが、重くなるためabstractを抽出してアブストラクトだけをresponses_abstに保存します\n",
    "\n",
    "for query in queries:\n",
    "      response = requests.get(query)\n",
    "      root = etree.fromstring(response.content)\n",
    "      pmid = root.find('.//PMID').text#pmidを抽出\n",
    "      abst = root.findall('.//AbstractText')\n",
    "      if abst is None:\n",
    "          abst_text = ''\n",
    "      else:\n",
    "          abst_text = ''.join(root.xpath('//Abstract//*/text()'))\n",
    "      responses_abst[pmid]=abst_text\n",
    "      time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e743030c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'36800255': 'Lesion segmentation is critical for clinicians to accurately stage the disease and determine treatment strategy. Deep learning based automatic segmentation can improve both the segmentation efficiency and accuracy. However, training a robust deep learning segmentation model requires sufficient training examples with sufficient diversity in lesion location and lesion size. This study is to develop a deep learning framework for generation of synthetic lesions with various locations and sizes that can be included in the training dataset to enhance the lesion segmentation performance. The lesion synthesis network is a modified generative adversarial network (GAN). Specifically, we innovated a partial convolution strategy to construct a U-Net-like generator. The discriminator is designed using Wasserstein GAN with gradient penalty and spectral normalization. A mask generation method based on principal component analysis (PCA) was developed to model various lesion shapes. The generated masks are then converted into liver lesions through a lesion synthesis network. The lesion synthesis framework was evaluated for lesion textures, and the synthetic lesions were used to train a lesion segmentation network to further validate the effectiveness of the lesion synthesis framework. All the networks are trained and tested on the LITS public dataset. Our experiments demonstrate that the synthetic lesions generated by our approach have very similar distributions for the two parameters, GLCM-energy and GLCM-correlation. Including the synthetic lesions in the segmentation network improved the segmentation dice performance from 67.3% to 71.4%. Meanwhile, the precision and sensitivity for lesion segmentation were improved from 74.6% to 76.0% and 66.1% to 70.9%, respectively. The proposed lesion synthesis approach outperforms the other two existing approaches. Including the synthetic lesion data into the training dataset significantly improves the segmentation performance.© 2023 The Authors. Journal of Applied Clinical Medical Physics published by Wiley Periodicals, LLC on behalf of The American Association of Physicists in Medicine.',\n",
       " '36800155': 'Automated classification of blood cells from microscopic images is an interesting research area owing to advancements of efficient neural network models. The existing deep learning methods rely on large data for network training and generating such large data could be time-consuming. Further, explainability is required via class activation mapping for better understanding of the model predictions. Therefore, we developed a Siamese twin network (STN) model based on contrastive learning that trains on relatively few images for the classification of healthy peripheral blood cells using EfficientNet-B3 as the base model. Hence, in this study, a total of 17,092 publicly accessible cell histology images were analyzed from which 6% were used for STN training, 6% for few-shot validation, and the rest 88% for few-shot testing. The proposed architecture demonstrates percent accuracies of 97.00, 98.78, 94.59, 95.70, 98.86, 97.09, 99.71, and 96.30 during 8-way 5-shot testing for the classification of basophils, eosinophils, immature granulocytes, erythroblasts, lymphocytes, monocytes, platelets, and neutrophils, respectively. Further, we propose a novel class activation mapping scheme that highlights the important regions in the test image for the STN model interpretability. Overall, the proposed framework could be used for a fully automated self-exploratory classification of healthy peripheral blood cells. The whole proposed framework demonstrates the Siamese twin network training and 8-way k-shot testing. The values indicate the amount of dissimilarity.© 2023. International Federation for Medical and Biological Engineering.',\n",
       " '36800143': 'In the management of the aortic aneurysm, 4D flow magnetic resonance Imaging provides valuable information for the computation of new biomarkers using computational fluid dynamics (CFD). However, accurate segmentation of the aorta is required. Thus, our objective is to evaluate the performance of two automatic segmentation methods on the calculation of aortic wall pressure.Automatic segmentation of the aorta was performed with methods based on deep learning and multi-atlas using the systolic phase in the 4D flow MRI magnitude image of 36 patients. Using mesh morphing, isotopological meshes were generated, and CFD was performed to calculate the aortic wall pressure. Node-to-node comparisons of the pressure results were made to identify the most robust automatic method respect to the pressures obtained with a manually segmented model.Deep learning approach presented the best segmentation performance with a mean Dice similarity coefficient and a mean Hausdorff distance (HD) equal to 0.92+/- 0.02 and 21.02+/- 24.20\\xa0mm, respectively. At the global level HD is affected by the performance in the abdominal aorta. Locally, this distance decreases to "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 5000 exceeded with 17782 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses_abst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725de20",
   "metadata": {},
   "source": [
    "# Trash (Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171b44fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PubMed\n",
      "File \u001b[1;32mD:\\soft\\Anaconda\\envs\\202302-pubmed\\lib\\site-packages\\pymed\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PubMed\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPubMed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\soft\\Anaconda\\envs\\202302-pubmed\\lib\\site-packages\\pymed\\api.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mElementTree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\n",
      "File \u001b[1;32mD:\\soft\\Anaconda\\envs\\202302-pubmed\\lib\\site-packages\\requests\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m charset_normalizer_version\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     charset_normalizer_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\soft\\Anaconda\\envs\\202302-pubmed\\lib\\site-packages\\charset_normalizer\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mCharset-Normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[1;32mD:\\soft\\Anaconda\\envs\\202302-pubmed\\lib\\site-packages\\charset_normalizer\\api.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     PathLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike[str]\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mess_ratio\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from pymed import PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37795928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed = PubMed(tool=\"MyTool\", email=\"my@email.address\")\n",
    "results = pubmed.query(\"Some query\", max_results=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
