{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7f8be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# ライブラリをインポートします\n",
    "from datetime import datetime\n",
    "import json\n",
    "from lxml import etree\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.styles import Border, Font, Side, PatternFill, Alignment\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "# Print for the iterations:\n",
    "# 1, 2, 3,..., 9,\n",
    "# 10, 20, 30,..., 90,\n",
    "# 100, 200, 300,..., 900,\n",
    "# ...\n",
    "def counter_print(i):\n",
    "    digit = int(np.log10(i))\n",
    "    if (i / (10 ** digit)).is_integer():\n",
    "        print(datetime.now().strftime('%Y/%m/%d %H:%M:%S'), \": processing entry #\", i)\n",
    "        \n",
    "\n",
    "# Get the PubmMed IDs with the search query `term`\n",
    "# termをPubMedにクエリとして投げ、結果をPubMed IDのリストとして返します\n",
    "def eSearch(term, retmax=10):\n",
    "    print(\"Fetching the list of PubMed IDs...\")\n",
    "    URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json'\n",
    "    option = '&retmax='+str(retmax)+'&term='+term\n",
    "    query = URL + option\n",
    "    response = requests.get(query)\n",
    "    response_json = response.json()\n",
    "    pmids = response_json['esearchresult']['idlist']\n",
    "    return pmids\n",
    "\n",
    "\n",
    "# Get summary statistics of the papers listed in `pmids` as pandas.DataFrame\n",
    "# PubMed IDのリストから、それぞれの論文に関するサマリを取得し、pandas.DataFrameとして返します\n",
    "def eSummary(pmids):\n",
    "    print(\"Fetching the summaries based on the ID list...\")\n",
    "    URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&retmode=json&id='\n",
    "    queries = [URL + pmid for pmid in pmids]\n",
    "    responses = {}\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        counter_print(i)\n",
    "        response = requests.get(query)\n",
    "        res_json = response.json()['result']\n",
    "        responses.update(res_json)\n",
    "        time.sleep(0.2)\n",
    "    Summaries = [{'pmid':pmid,\n",
    "                  'Title':responses[pmid]['title'], \n",
    "                  'Author':responses[pmid]['sortfirstauthor'],\n",
    "                  'Journal_full' : responses[pmid]['fulljournalname'],\n",
    "                  'Journal_abbr' : responses[pmid]['source'],\n",
    "                  'Pubdate':responses[pmid]['epubdate']} for pmid in pmids]\n",
    "    return pd.DataFrame(Summaries)\n",
    "\n",
    "\n",
    "# Get the abstracts of the papers listed in `pmids` as pandas.DataFrame\n",
    "# PubMed IDのリストから、それぞれの論文のAbstractを取得し、pandas.DataFrameとして返します\n",
    "def eFetch(pmids):\n",
    "    print(\"Fetching the abstracts based on the ID list...\")\n",
    "    URL = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&retmode=xml&id='\n",
    "    queries = [URL + pmid for pmid in pmids]\n",
    "    responses_abst = {}\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        counter_print(i)\n",
    "        response = requests.get(query)\n",
    "        root = etree.fromstring(response.content)\n",
    "        pmid = root.find('.//PMID').text #pmidを抽出\n",
    "        abst = root.findall('.//AbstractText')\n",
    "        if abst is None:\n",
    "            abst_text = ''\n",
    "        else:\n",
    "            abst_text = ''.join(root.xpath('//Abstract//*/text()'))\n",
    "        responses_abst[pmid]=abst_text\n",
    "        time.sleep(0.2)\n",
    "        abst_df = pd.DataFrame.from_dict(responses_abst, orient='index')\n",
    "        abst_df.index.name = 'pmid'\n",
    "        abst_df.columns = ['Abstract']\n",
    "    return abst_df\n",
    "\n",
    "\n",
    "# Export as .xlsx\n",
    "# 結果を.xlsxファイルとして出力します\n",
    "def to_excel(data, filename):\n",
    "    wb = openpyxl.Workbook() #ワークブックの作成\n",
    "    ws = wb.active #ワークブックのアクティブになってるシートを選択\n",
    "    ws.title='論文' #シートの名前を変更\n",
    "\n",
    "    #フォントの設定\n",
    "    normal_font = Font(name = \"Century Gothic\",sz = 9,b = False)\n",
    "    header_font = Font(name = \"Century Gothic\", sz = 9, b = True, color = 'FFFFFFFF')\n",
    "    #ヘッダーの塗りの設定\n",
    "    header_fill = PatternFill(patternType = \"solid\", fgColor = \"FF808080\")\n",
    "    #ヘッダーを中央揃えにする設定\n",
    "    header_center = Alignment(horizontal='center',vertical = 'center')    \n",
    "    #ヘッダーを太字にする設定\n",
    "    header_border = Border(\n",
    "            outline=True,\n",
    "            left=Side(style='thin', color='FF000000'),\n",
    "            right=Side(style='thin', color='FF000000'),\n",
    "            top=Side(style='thin', color='FF000000'),\n",
    "            bottom=Side(style='thin', color='FF000000')\n",
    "            )\n",
    "\n",
    "    for r in dataframe_to_rows(data, index=False, header=True):\n",
    "        ws.append(r)\n",
    "\n",
    "    for row in ws:\n",
    "        for cell in row:\n",
    "            cell.font = normal_font\n",
    "\n",
    "    header_cell = ['A1', 'B1', 'C1', 'D1', 'E1']\n",
    "    for cell in header_cell:\n",
    "        ws[cell].font = header_font\n",
    "        ws[cell].fill = header_fill\n",
    "        ws[cell].alignment = header_center\n",
    "        ws[cell].border = header_border\n",
    "\n",
    "    wb.save(filename)\n",
    "    print(\"Exported as:\", filename)\n",
    "\n",
    "\n",
    "# Export PubMed ID + Title + Abstract to .txt\n",
    "# PubMed ID、タイトル、Abstractを結合したものを.txtファイルに出力します\n",
    "def to_chat_AI(data, filename):\n",
    "    l_data = data[[\"pmid\", \"Title\", \"Abstract\"]].values.tolist()\n",
    "    l_data = [\"pmid:\" + l[0] + \", title:\" + l[1] + \", abstract:\" + l[2] for l in l_data]\n",
    "    str_data = \"\\n\\n\".join(l_data)\n",
    "    with open(filename, \"w\", encoding='UTF-8') as f:\n",
    "        f.write(str_data)\n",
    "    print(\"Exported as:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e4dd16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching the list of PubMed IDs...\n",
      "Fetching the summaries based on the ID list...\n",
      "2023/02/21 14:55:56 : processing entry # 1\n",
      "2023/02/21 14:55:57 : processing entry # 2\n",
      "2023/02/21 14:55:58 : processing entry # 3\n",
      "2023/02/21 14:55:59 : processing entry # 4\n",
      "2023/02/21 14:56:00 : processing entry # 5\n",
      "2023/02/21 14:56:01 : processing entry # 6\n",
      "2023/02/21 14:56:02 : processing entry # 7\n",
      "2023/02/21 14:56:03 : processing entry # 8\n",
      "2023/02/21 14:56:04 : processing entry # 9\n",
      "2023/02/21 14:56:05 : processing entry # 10\n",
      "Fetching the abstracts based on the ID list...\n",
      "2023/02/21 14:56:06 : processing entry # 1\n",
      "2023/02/21 14:56:07 : processing entry # 2\n",
      "2023/02/21 14:56:08 : processing entry # 3\n",
      "2023/02/21 14:56:09 : processing entry # 4\n",
      "2023/02/21 14:56:10 : processing entry # 5\n",
      "2023/02/21 14:56:11 : processing entry # 6\n",
      "2023/02/21 14:56:12 : processing entry # 7\n",
      "2023/02/21 14:56:13 : processing entry # 8\n",
      "2023/02/21 14:56:14 : processing entry # 9\n",
      "2023/02/21 14:56:15 : processing entry # 10\n"
     ]
    }
   ],
   "source": [
    "# Set the query - where \"%20\" is a space character.\n",
    "# PubMedに投げるクエリ。「%20」はスペースです。\n",
    "term = 'deep%20learning'\n",
    "\n",
    "# Get the PubmMed IDs with the search query `term`\n",
    "# termをPubMedにクエリとして投げ、結果をPubMed IDのリストとして返します\n",
    "pmids = eSearch(term)\n",
    "# Maximum output can be increased by \"pmids = eSearch(term, retmax=100)\" for example\n",
    "# デフォルトでは10個までですが、変更する際はpmids = eSearch(term, retmax=100)などを入れます。\n",
    "\n",
    "# Get summary statistics of the papers listed in `pmids`, as pandas.DataFrame\n",
    "# PubMed IDのリストから、それぞれの論文に関するサマリを取得し、pandas.DataFrameとして返します\n",
    "summary_df = eSummary(pmids)\n",
    "\n",
    "# Get the abstracts of the papers listed in `pmids` as pandas.DataFrame\n",
    "# PubMed IDのリストから、それぞれの論文のAbstractを取得し、pandas.DataFrameとして返します\n",
    "abst_df = eFetch(pmids)\n",
    "\n",
    "# Merge the summary statistics & abstracts\n",
    "# サマリとAbstractを統合し一つのpandas.DataFrameとします。\n",
    "df = pd.merge(summary_df, abst_df, on='pmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "938e18a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Journal_full</th>\n",
       "      <th>Journal_abbr</th>\n",
       "      <th>Pubdate</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36800255</td>\n",
       "      <td>A partial convolution generative adversarial n...</td>\n",
       "      <td>Liu Y</td>\n",
       "      <td>Journal of applied clinical medical physics</td>\n",
       "      <td>J Appl Clin Med Phys</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Lesion segmentation is critical for clinicians...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36800155</td>\n",
       "      <td>Few-shot learning using explainable Siamese tw...</td>\n",
       "      <td>Tummala S</td>\n",
       "      <td>Medical &amp; biological engineering &amp; computing</td>\n",
       "      <td>Med Biol Eng Comput</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Automated classification of blood cells from m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36800143</td>\n",
       "      <td>Segmentation of the aorta in systolic phase fr...</td>\n",
       "      <td>Marin-Castrillon DM</td>\n",
       "      <td>Magma (New York, N.Y.)</td>\n",
       "      <td>MAGMA</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>In the management of the aortic aneurysm, 4D f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36800112</td>\n",
       "      <td>Diagnostic performance of deep learning-based ...</td>\n",
       "      <td>Yang W</td>\n",
       "      <td>La Radiologia medica</td>\n",
       "      <td>Radiol Med</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Post-processing and interpretation of coronary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36799660</td>\n",
       "      <td>Using Explainable Artificial Intelligence in t...</td>\n",
       "      <td>Jiménez-Mesa C</td>\n",
       "      <td>International journal of neural systems</td>\n",
       "      <td>Int J Neural Syst</td>\n",
       "      <td>2023 Feb 16</td>\n",
       "      <td>The prevalence of dementia is currently increa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36799418</td>\n",
       "      <td>An innovative metal artifact reduction algorit...</td>\n",
       "      <td>Zhang Z</td>\n",
       "      <td>Current medical imaging</td>\n",
       "      <td>Curr Med Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>During X-ray computed tomography (CT) scans, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36799417</td>\n",
       "      <td>Cancer detection based on Medical Image Analys...</td>\n",
       "      <td>Sood T</td>\n",
       "      <td>Current medical imaging</td>\n",
       "      <td>Curr Med Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Cancer is a deadly disease. It is crucial to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36799341</td>\n",
       "      <td>Implementable Deep Learning for Multi-sequence...</td>\n",
       "      <td>Astley JR</td>\n",
       "      <td>Journal of magnetic resonance imaging : JMRI</td>\n",
       "      <td>J Magn Reson Imaging</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Recently, deep learning via convolutional neur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36799277</td>\n",
       "      <td>Micromirrors in Neurosurgery: Technical Overvi...</td>\n",
       "      <td>Ordóñez-Rubiano EG</td>\n",
       "      <td>Turkish neurosurgery</td>\n",
       "      <td>Turk Neurosurg</td>\n",
       "      <td>2022 Aug 26</td>\n",
       "      <td>Micromirrors are 45°-angled reflectors able to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36799198</td>\n",
       "      <td>Construction of Exosome SORL1 Detection Platfo...</td>\n",
       "      <td>Li P</td>\n",
       "      <td>Small (Weinheim an der Bergstrasse, Germany)</td>\n",
       "      <td>Small</td>\n",
       "      <td>2023 Feb 17</td>\n",
       "      <td>Exosomes are promising new biomarkers for colo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                              Title  \\\n",
       "0  36800255  A partial convolution generative adversarial n...   \n",
       "1  36800155  Few-shot learning using explainable Siamese tw...   \n",
       "2  36800143  Segmentation of the aorta in systolic phase fr...   \n",
       "3  36800112  Diagnostic performance of deep learning-based ...   \n",
       "4  36799660  Using Explainable Artificial Intelligence in t...   \n",
       "5  36799418  An innovative metal artifact reduction algorit...   \n",
       "6  36799417  Cancer detection based on Medical Image Analys...   \n",
       "7  36799341  Implementable Deep Learning for Multi-sequence...   \n",
       "8  36799277  Micromirrors in Neurosurgery: Technical Overvi...   \n",
       "9  36799198  Construction of Exosome SORL1 Detection Platfo...   \n",
       "\n",
       "                Author                                  Journal_full  \\\n",
       "0                Liu Y   Journal of applied clinical medical physics   \n",
       "1            Tummala S  Medical & biological engineering & computing   \n",
       "2  Marin-Castrillon DM                        Magma (New York, N.Y.)   \n",
       "3               Yang W                          La Radiologia medica   \n",
       "4       Jiménez-Mesa C       International journal of neural systems   \n",
       "5              Zhang Z                       Current medical imaging   \n",
       "6               Sood T                       Current medical imaging   \n",
       "7            Astley JR  Journal of magnetic resonance imaging : JMRI   \n",
       "8   Ordóñez-Rubiano EG                          Turkish neurosurgery   \n",
       "9                 Li P  Small (Weinheim an der Bergstrasse, Germany)   \n",
       "\n",
       "           Journal_abbr      Pubdate  \\\n",
       "0  J Appl Clin Med Phys  2023 Feb 17   \n",
       "1   Med Biol Eng Comput  2023 Feb 17   \n",
       "2                 MAGMA  2023 Feb 17   \n",
       "3            Radiol Med  2023 Feb 17   \n",
       "4     Int J Neural Syst  2023 Feb 16   \n",
       "5      Curr Med Imaging  2023 Feb 17   \n",
       "6      Curr Med Imaging  2023 Feb 17   \n",
       "7  J Magn Reson Imaging  2023 Feb 17   \n",
       "8        Turk Neurosurg  2022 Aug 26   \n",
       "9                 Small  2023 Feb 17   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Lesion segmentation is critical for clinicians...  \n",
       "1  Automated classification of blood cells from m...  \n",
       "2  In the management of the aortic aneurysm, 4D f...  \n",
       "3  Post-processing and interpretation of coronary...  \n",
       "4  The prevalence of dementia is currently increa...  \n",
       "5  During X-ray computed tomography (CT) scans, t...  \n",
       "6  Cancer is a deadly disease. It is crucial to d...  \n",
       "7  Recently, deep learning via convolutional neur...  \n",
       "8  Micromirrors are 45°-angled reflectors able to...  \n",
       "9  Exosomes are promising new biomarkers for colo...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result is something like this\n",
    "# 中身はこのようになります\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47ed7b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported as: test3.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Export as .xlsx\n",
    "# 結果を.xlsxファイルとして出力します\n",
    "to_excel(df, \"test3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69b3bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported as: test3.txt\n"
     ]
    }
   ],
   "source": [
    "# Export PubMed ID + Title + Abstract to .txt\n",
    "# PubMed ID、タイトル、Abstractを結合したものを.txtファイルに出力します\n",
    "to_chat_AI(df, \"test3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862079d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
